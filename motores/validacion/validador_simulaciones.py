"""
M√≥dulo de validaci√≥n de simulaciones para los modelos Vasicek y Hull-White.
Calcula m√©tricas de bondad de ajuste: R¬≤, RMSE y MAE.

==============================================================================
METODOLOG√çA DE VALIDACI√ìN DE CALIBRACI√ìN
==============================================================================

Este m√≥dulo implementa la validaci√≥n de par√°metros calibrados mediante MLE
(Maximum Likelihood Estimation) comparando datos hist√≥ricos vs predicciones.

VASICEK:
--------
Calibramos (Œ∫, Œ∏, œÉ) con MLE sobre serie hist√≥rica de tasas
Validamos:
  1. Reconstruimos serie completa: rÃÇ‚Çú = Œ∏ + (rÃÇ‚Çú‚Çã‚ÇÅ - Œ∏)e^(-Œ∫Œît)
  2. Comparamos: r_hist√≥rico vs rÃÇ_predicho
  3. M√©tricas: R¬≤, RMSE, MAE

HULL-WHITE:
-----------
Calibramos (a, œÉ, Œª) + Œ∏(t) con MLE sobre serie de overnight + curva forward
Validamos:
  1. Usamos Œ∏(t) calibrado para predecir curva de tasas
  2. Comparamos: curva_hist√≥rica vs curva_predicha(Œ∏)
  3. M√©tricas: R¬≤, RMSE, MAE

==============================================================================
"""

import numpy as np
import pandas as pd
import logging
from typing import Dict, Tuple, Optional

logger = logging.getLogger(__name__)


class ValidadorSimulaciones:
    """
    Validador de simulaciones estoc√°sticas para modelos de tasas de inter√©s.
    Implementa m√©tricas de bondad de ajuste y diagn√≥sticos estad√≠sticos.
    """
    
    def __init__(self):
        self.resultados_validacion = {}
        self.metricas_globales = {}
        
    def validar_vasicek(
        self,
        df_tasas_historicas: pd.DataFrame,
        parametros_calibrados: Dict[str, Dict[str, float]],
        df_creditos: Optional[pd.DataFrame] = None,
    ) -> Dict:
        """
        Valida CALIBRACI√ìN del modelo Vasicek comparando tasas hist√≥ricas vs predichas.
        
        METODOLOG√çA:
        ------------
        1. DATOS DE ENTRADA:
           - Serie hist√≥rica de tasas EA (Tasa Efectiva Anual) por tipo de cr√©dito
           - Par√°metros calibrados (Œ∫, Œ∏, œÉ) obtenidos por MLE en short rate space
        
        2. PROCESO DE VALIDACI√ìN:
           a) Transformaci√≥n: EA ‚Üí Short Rate usando r = ln(1 + EA)
           b) Para cada observaci√≥n t, calcular:
              ‚Ä¢ Media condicional: E[r‚Çú|r‚Çú‚Çã‚ÇÅ] = Œ∏ + (r‚Çú‚Çã‚ÇÅ - Œ∏)¬∑e^(-Œ∫Œît)
           c) Comparar tasas observadas vs predichas
        
        3. M√âTRICAS CALCULADAS:
           ‚úÖ R¬≤: Coeficiente de determinaci√≥n
           ‚úÖ RMSE: Error cuadr√°tico medio
           ‚úÖ MAE: Error absoluto medio
        
        Args:
            df_tasas_historicas: DataFrame con tasas hist√≥ricas por tipo (EA)
            parametros_calibrados: Dict con par√°metros {tipo: {'kappa': Œ∫, 'theta': Œ∏, 'sigma': œÉ}}
            df_creditos: DataFrame opcional con informaci√≥n de cr√©ditos
            
        Returns:
            Dict con m√©tricas R¬≤, RMSE, MAE por tipo de cr√©dito
        """
        logger.info("üìä Iniciando validaci√≥n de CALIBRACI√ìN Vasicek...")
        
        resultados = {
            'modelo': 'Vasicek',
            'tipos_validados': [],
            'metricas_por_tipo': {},
            'metricas_globales': {}
        }
        
        # DIAGN√ìSTICO: Verificar estructura del DataFrame recibido
        logger.info(f"üîç DIAGN√ìSTICO - Estructura DataFrame recibido:")
        logger.info(f"   Columnas: {list(df_tasas_historicas.columns)}")
        logger.info(f"   Shape: {df_tasas_historicas.shape}")
        logger.info(f"   Index type: {type(df_tasas_historicas.index)}")
        logger.info(f"   Primeras filas:\n{df_tasas_historicas.head()}")
        
        for tipo_credito, params in parametros_calibrados.items():
            logger.info(f"üîç Validando calibraci√≥n tipo: {tipo_credito}")
            logger.info(f"   Par√°metros recibidos: kappa={params.get('kappa')}, theta={params.get('theta')}, sigma={params.get('sigma')}")
            
            # Extraer tasas hist√≥ricas del tipo
            if tipo_credito not in df_tasas_historicas.columns:
                logger.warning(f"‚ö†Ô∏è Tipo {tipo_credito} no encontrado en hist√≥ricos")
                logger.warning(f"   Columnas disponibles: {list(df_tasas_historicas.columns)}")
                continue
            
            tasas_hist_ea = df_tasas_historicas[tipo_credito].dropna().values
            logger.info(f"   üìä Datos extra√≠dos: {len(tasas_hist_ea)} observaciones")
            logger.info(f"   Rango valores: [{tasas_hist_ea.min():.6f}, {tasas_hist_ea.max():.6f}]")
            
            # Normalizar si est√°n en porcentaje
            if tasas_hist_ea.max() > 1.0:
                logger.info(f"   ¬∑ Normalizando desde porcentaje (max={tasas_hist_ea.max():.2f})")
                tasas_hist_ea = tasas_hist_ea / 100.0
                logger.info(f"   ¬∑ Despu√©s de normalizar: [{tasas_hist_ea.min():.6f}, {tasas_hist_ea.max():.6f}]")
            
            # Convertir EA a short rate: r = ln(1 + EA)
            tasas_hist_short = np.log1p(tasas_hist_ea)  # ln(1 + x)
            logger.info(f"   üîÑ Transformaci√≥n EA ‚Üí Short Rate:")
            logger.info(f"      EA: [{tasas_hist_ea.min():.6f}, {tasas_hist_ea.max():.6f}]")
            logger.info(f"      Short: [{tasas_hist_short.min():.6f}, {tasas_hist_short.max():.6f}]")
            logger.info(f"      Media Short: {tasas_hist_short.mean():.6f}")
            
            # EXTRAER PAR√ÅMETROS CALIBRADOS
            kappa = params.get('kappa', 0.2)
            theta = params.get('theta', 0.05)
            sigma = params.get('sigma', 0.01)
            
            logger.info(f"   üìã Par√°metros para validaci√≥n:")
            logger.info(f"      Œ∫={kappa:.6f}, Œ∏={theta:.6f}, œÉ={sigma:.6f}")
            
            dt = 7/365.0  # Paso semanal (mismo que calibraci√≥n MLE)
            
            # Inicializar serie predicha
            n = len(tasas_hist_short)
            exp_kdt = np.exp(-kappa * dt)
            
            # Calcular predicciones (1-paso adelante)
            predicciones_media = np.zeros(n-1)
            
            for t in range(n-1):
                # Media condicional: E[r_t | r_{t-1}]
                predicciones_media[t] = theta + (tasas_hist_short[t] - theta) * exp_kdt
            
            logger.info(f"   ‚úÖ Predicciones calculadas: {len(predicciones_media)} observaciones")

            # M√âTRICAS DE AJUSTE (R¬≤, RMSE, MAE) EN SHORT RATE SPACE
            metricas_fit = self._calcular_metricas(
                observado=tasas_hist_short[1:],
                simulado=predicciones_media
            )
            
            # Logging de resultados
            logger.info(f"   üìä M√âTRICAS DE VALIDACI√ìN:")
            logger.info(f"      R¬≤: {metricas_fit['r_cuadrado']:.4f}")
            logger.info(f"      RMSE: {metricas_fit['rmse']:.6f}")
            logger.info(f"      MAE: {metricas_fit['mae']:.6f}")
            
            # Construir dict de m√©tricas
            metricas = {
                'r_cuadrado': round(float(metricas_fit['r_cuadrado']), 4),
                'rmse': round(float(metricas_fit['rmse']), 6),
                'mae': round(float(metricas_fit['mae']), 6),
                'correlacion': round(float(metricas_fit['correlacion']), 4),
                'sesgo': round(float(metricas_fit['sesgo']), 6),
                'parametros': {
                    'kappa': round(float(kappa), 6),
                    'theta': round(float(theta), 6),
                    'sigma': round(float(sigma), 6)
                },
                'n_observaciones': int(n),
                'espacio_validacion': 'short_rate'
            }
            
            resultados['tipos_validados'].append(tipo_credito)
            resultados['metricas_por_tipo'][tipo_credito] = metricas
            
            logger.info(f"‚úÖ {tipo_credito}: R¬≤={metricas_fit['r_cuadrado']:.4f}, RMSE={metricas_fit['rmse']:.6f}, MAE={metricas_fit['mae']:.6f}")
        
        # Replicar m√©tricas por cr√©dito si se dispone de df_creditos
        if df_creditos is not None:
            try:
                resultados['creditos_validados'] = []
                resultados['metricas_por_credito'] = {}
                # Columnas esperadas: 'ID_producto', 'Tipo_producto'
                if 'ID_producto' in df_creditos.columns and 'Tipo_producto' in df_creditos.columns:
                    for _, row in df_creditos.iterrows():
                        id_credito = row['ID_producto']
                        tipo = row['Tipo_producto']
                        if tipo in resultados['metricas_por_tipo']:
                            m_tipo = resultados['metricas_por_tipo'][tipo]
                            m_credito = {
                                'r_cuadrado': m_tipo.get('r_cuadrado'),
                                'rmse': m_tipo.get('rmse'),
                                'mae': m_tipo.get('mae'),
                                'correlacion': m_tipo.get('correlacion'),
                                'sesgo': m_tipo.get('sesgo'),
                                'n_observaciones': m_tipo.get('n_observaciones'),
                                'tipo': tipo
                            }
                            resultados['creditos_validados'].append(id_credito)
                            resultados['metricas_por_credito'][id_credito] = m_credito
                else:
                    logger.warning("‚ö†Ô∏è df_creditos no contiene columnas 'ID_producto' y 'Tipo_producto'. Se omite expansi√≥n por cr√©dito.")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è No fue posible expandir m√©tricas por cr√©dito: {e}")

        # Calcular m√©tricas globales
        if resultados['metricas_por_tipo']:
            # Promedios de m√©tricas
            r2_promedio = np.mean([m.get('r_cuadrado', np.nan) for m in resultados['metricas_por_tipo'].values()])
            rmse_promedio = np.mean([m['rmse'] for m in resultados['metricas_por_tipo'].values()])
            mae_promedio = np.mean([m['mae'] for m in resultados['metricas_por_tipo'].values()])
            
            resultados['metricas_globales'] = {
                'r_cuadrado_promedio': round(float(r2_promedio), 4) if not np.isnan(r2_promedio) else None,
                'rmse_promedio': round(rmse_promedio, 6),
                'mae_promedio': round(mae_promedio, 6)
            }
        
        self.resultados_validacion['Vasicek'] = resultados
        logger.info(f"‚úÖ Validaci√≥n calibraci√≥n Vasicek completada: {len(resultados['tipos_validados'])} tipos")
        
        return resultados
    
    def validar_hull_white(
        self,
        df_curva_hw: pd.DataFrame,
        parametros_calibrados: Dict[str, Dict[str, float]],
        fecha_corte: pd.Timestamp
    ) -> Dict:
        """
        Valida CALIBRACI√ìN Hull-White comparando tasas hist√≥ricas vs predichas.
        
        METODOLOG√çA:
        ------------
        1. DATOS DE ENTRADA:
           - Serie hist√≥rica de curvas de tasas (CurvaHW)
           - Par√°metros calibrados (a, œÉ, Œª) + funci√≥n Œ∏(t) por cr√©dito
        
        2. PROCESO DE VALIDACI√ìN:
           a) Predecir tasas usando par√°metros calibrados
           b) Comparar tasas observadas vs predichas
        
        3. M√âTRICAS CALCULADAS:
           ‚úÖ R¬≤: Coeficiente de determinaci√≥n
           ‚úÖ RMSE: Error cuadr√°tico medio
           ‚úÖ MAE: Error absoluto medio
        
        Args:
            df_curva_hw: DataFrame con curva de tasas hist√≥ricas
            parametros_calibrados: Dict con par√°metros por cr√©dito
            fecha_corte: Fecha de corte de la validaci√≥n
            
        Returns:
            Dict con m√©tricas R¬≤, RMSE, MAE por cr√©dito
        """
        logger.info("üìä Iniciando validaci√≥n de CALIBRACI√ìN Hull-White...")
        
        resultados = {
            'modelo': 'Hull-White',
            'creditos_validados': [],
            'metricas_por_credito': {},
            'metricas_globales': {}
        }
        
        # Construir hist√≥rico hasta fecha de corte
        df_hw = df_curva_hw.copy()
        df_hw['Fecha'] = pd.to_datetime(df_hw['Fecha'], dayfirst=True)
        df_hist = df_hw[df_hw['Fecha'] <= fecha_corte].sort_values('Fecha')
        if df_hist.empty:
            logger.warning("‚ö†Ô∏è No hay datos hist√≥ricos de curva para validaci√≥n")
            return resultados
        
        # Detectar nodos num√©ricos
        all_cols = [c for c in df_hist.columns if c != 'Fecha']
        nodos = []
        for c in all_cols:
            s = str(c)
            if s.isdigit():
                try:
                    nodos.append(int(s))
                except Exception:
                    pass
        nodos = np.array(sorted(set(nodos)), dtype=int)
        if len(nodos) < 2:
            logger.warning("‚ö†Ô∏è Nodos insuficientes en CurvaHW para validar")
            return resultados
        cols = [str(n) for n in nodos]
        curvas_ea = df_hist[cols].astype(float).values
        try:
            max_val = float(np.nanmax(curvas_ea))
            if max_val > 1.0 and max_val <= 100.0:
                curvas_ea = curvas_ea / 100.0
        except Exception:
            pass
        taus = nodos / 365.0
        curvas_cont = np.log1p(curvas_ea)
        fwds = np.apply_along_axis(lambda row: np.gradient(-row * taus, taus, edge_order=2) * -1, 1, curvas_cont)
        r_short_fw0 = fwds[:, 0]
        fechas = pd.to_datetime(df_hist['Fecha']).values
        
        # Serie overnight (short rate)
        if 1 in nodos:
            idx1 = int(np.where(nodos == 1)[0][0])
            r_series = np.log1p(curvas_ea[:, idx1]).astype(float)
        else:
            r_series = r_short_fw0.astype(float)
        
        # Tiempos entre observaciones
        dts = np.diff(fechas) / np.timedelta64(1, 'D')
        dts = dts.astype(float) / 365.0
        dts = np.clip(dts, 1.0/365.0, None)
        j_days = np.maximum((np.round(dts * 365.0)).astype(int), 1)
        j_idx = np.minimum(j_days - 1, fwds.shape[1] - 1)
        n = len(r_series)
        m = int(min(len(dts), n - 1, fwds.shape[0] - 1))
        if m <= 0:
            logger.warning("‚ö†Ô∏è Hist√≥rico insuficiente para validar Hull-White")
            return resultados
        j_idx = j_idx[:m]
        
        # Validar cada cr√©dito con sus par√°metros
        for id_credito, params in parametros_calibrados.items():
            logger.info(f"üîç Validando calibraci√≥n cr√©dito: {id_credito}")
            try:
                a = params.get('a', 0.1)
                sigma = params.get('sigma', 0.01)
                lambda_param = params.get('lambda', params.get('lambda_', 0.0))
            except AttributeError:
                a = getattr(params, 'a', 0.1)
                sigma = getattr(params, 'sigma', 0.01)
                lambda_param = getattr(params, 'lambda_', 0.0)
            
            pred = np.zeros(m, dtype=float)
            obs = np.zeros(m, dtype=float)
            for k in range(m):
                dt = float(dts[k])
                j = int(j_idx[k])
                f_dt = float(fwds[k, j])
                one = 1.0 - np.exp(-a * dt)
                exp_term = np.exp(-a * dt)
                mean_q = exp_term * (r_series[k] - r_short_fw0[k]) + f_dt + (sigma**2 / (2.0 * a**2)) * (one**2)
                mean = mean_q + (sigma * lambda_param / a) * one
                x = float(r_series[k + 1])
                pred[k] = mean
                obs[k] = x
            
            metricas_fit = self._calcular_metricas(observado=obs, simulado=pred)
            
            metricas = {
                'r_cuadrado': round(float(metricas_fit['r_cuadrado']), 4),
                'rmse': round(float(metricas_fit['rmse']), 6),
                'mae': round(float(metricas_fit['mae']), 6),
                'correlacion': round(float(metricas_fit['correlacion']), 4),
                'sesgo': round(float(metricas_fit['sesgo']), 6),
                'n_observaciones': int(m),
                'parametros': {
                    'a': round(float(a), 6),
                    'sigma': round(float(sigma), 6),
                    'lambda': round(float(lambda_param), 6)
                },
                'espacio_validacion': 'short_rate_ts'
            }
            resultados['creditos_validados'].append(id_credito)
            resultados['metricas_por_credito'][id_credito] = metricas
            logger.info(f"‚úÖ {id_credito}: R¬≤={metricas['r_cuadrado']:.4f}, RMSE={metricas['rmse']:.6f}, MAE={metricas['mae']:.6f}")
        
        # Calcular m√©tricas globales
        if resultados['metricas_por_credito']:
            r2_promedio = np.mean([m['r_cuadrado'] for m in resultados['metricas_por_credito'].values()])
            rmse_promedio = np.mean([m['rmse'] for m in resultados['metricas_por_credito'].values()])
            mae_promedio = np.mean([m['mae'] for m in resultados['metricas_por_credito'].values()])
            
            resultados['metricas_globales'] = {
                'r_cuadrado_promedio': round(r2_promedio, 4),
                'rmse_promedio': round(rmse_promedio, 6),
                'mae_promedio': round(mae_promedio, 6)
            }
        
        self.resultados_validacion['Hull-White'] = resultados
        logger.info(f"‚úÖ Validaci√≥n calibraci√≥n Hull-White completada: {len(resultados['creditos_validados'])} cr√©ditos")
        
        return resultados
    
    def _calcular_metricas(self, observado: np.ndarray, simulado: np.ndarray) -> Dict:
        """
        Calcula m√©tricas de bondad de ajuste entre series observadas y simuladas.
        
        M√âTRICAS IMPLEMENTADAS:
        -----------------------
        1. R¬≤ (Coeficiente de Determinaci√≥n):
           R¬≤ = 1 - SS_res/SS_tot = 1 - Œ£(Y_obs - Y_pred)¬≤/Œ£(Y_obs - »≤)¬≤
           Rango: [-‚àû, 1]. Valores m√°s cercanos a 1 indican mejor ajuste.
           Interpretaci√≥n: % de varianza explicada por el modelo.
        
        2. RMSE (Root Mean Square Error):
           RMSE = ‚àö[1/n¬∑Œ£(Y_obs - Y_pred)¬≤]
           Unidades: mismas que Y. Penaliza errores grandes.
           Interpretaci√≥n: error promedio "t√≠pico" del modelo.
        
        3. MAE (Mean Absolute Error):
           MAE = 1/n¬∑Œ£|Y_obs - Y_pred|
           Unidades: mismas que Y. Menos sensible a outliers que RMSE.
           Interpretaci√≥n: error promedio absoluto.
        
        4. Correlaci√≥n de Pearson:
           œÅ = Cov(Y_obs, Y_pred) / (œÉ_obs ¬∑ œÉ_pred)
           Rango: [-1, 1]. Mide asociaci√≥n lineal.
        
        5. Sesgo (Bias):
           Bias = mean(Y_pred - Y_obs)
           Positivo: modelo sobre-estima. Negativo: sub-estima.
        
        Args:
            observado: Serie observada (hist√≥rica)
            simulado: Serie simulada (predicha por modelo)
            
        Returns:
            Dict con m√©tricas: R¬≤, RMSE, MAE, correlaci√≥n, MAPE, sesgo
        """
        # Asegurar que ambas series tienen la misma longitud
        n = min(len(observado), len(simulado))
        obs = observado[:n]
        sim = simulado[:n]
        
        # R¬≤ (coeficiente de determinaci√≥n)
        # F√≥rmula: R¬≤ = 1 - SS_res/SS_tot
        # donde SS_res = suma de cuadrados residual
        #       SS_tot = suma de cuadrados total
        ss_res = np.sum((obs - sim) ** 2)  # Œ£(Y_obs - Y_pred)¬≤
        ss_tot = np.sum((obs - np.mean(obs)) ** 2)  # Œ£(Y_obs - »≤)¬≤
        
        # Manejo robusto: si no hay varianza (serie constante), R¬≤ indefinido ‚Üí 0
        if ss_tot > 1e-12:  # Evitar divisi√≥n por cero num√©rico
            r_cuadrado = 1 - (ss_res / ss_tot)
            # DIAGN√ìSTICO: Alertar si R¬≤ es negativo
            if r_cuadrado < 0:
                logger.warning(f"‚ö†Ô∏è R¬≤ NEGATIVO: {r_cuadrado:.4f}")
                logger.warning(f"   SS_res={ss_res:.8f} > SS_tot={ss_tot:.8f}")
                logger.warning(f"   El modelo predice PEOR que la media")
        else:
            r_cuadrado = 0.0
            logger.warning("‚ö†Ô∏è Serie observada tiene varianza ~0. R¬≤ establecido en 0.")
        
        # RMSE (Root Mean Square Error)
        rmse = np.sqrt(np.mean((obs - sim) ** 2))
        
        # MAE (Mean Absolute Error)
        mae = np.mean(np.abs(obs - sim))
        
        # Correlaci√≥n de Pearson
        if len(obs) > 1 and np.std(obs) > 0 and np.std(sim) > 0:
            correlacion = np.corrcoef(obs, sim)[0, 1]
        else:
            correlacion = 0.0
        
        # MAPE (Mean Absolute Percentage Error) - solo si no hay ceros
        if np.all(obs != 0):
            mape = np.mean(np.abs((obs - sim) / obs)) * 100
        else:
            mape = None
        
        metricas = {
            'r_cuadrado': round(float(r_cuadrado), 4),
            'rmse': round(float(rmse), 6),
            'mae': round(float(mae), 6),
            'correlacion': round(float(correlacion), 4),
            'mape': round(float(mape), 2) if mape is not None else None,
            'sesgo': round(float(np.mean(sim - obs)), 6)
        }
        
        return metricas
    
    def generar_reporte_completo(self) -> pd.DataFrame:
        """
        Genera un DataFrame consolidado con todas las m√©tricas de validaci√≥n.
        
        Returns:
            DataFrame con resumen de validaciones por modelo
        """
        logger.info("üìã Generando reporte consolidado de validaci√≥n...")
        
        reporte = []
        
        for modelo, resultados in self.resultados_validacion.items():
            metricas_globales = resultados.get('metricas_globales', {})
            
            fila = {
                'Modelo': modelo,
                'Entidades_Validadas': len(resultados.get('tipos_validados', []) or 
                                           resultados.get('creditos_validados', []))
            }
            
            # Para todos los modelos: usar R¬≤ si est√° disponible
            r2_prom = metricas_globales.get('r_cuadrado_promedio')
            fila['R¬≤_Promedio'] = r2_prom
            
            fila['RMSE_Promedio'] = metricas_globales.get('rmse_promedio')
            fila['MAE_Promedio'] = metricas_globales.get('mae_promedio')
            
            reporte.append(fila)
        
        df_reporte = pd.DataFrame(reporte)
        logger.info(f"‚úÖ Reporte generado: {len(df_reporte)} modelos validados")
        
        return df_reporte
    
    def obtener_datos_graficos(self, modelo: str, entidad: str = None) -> Dict:
        """
        Obtiene datos preparados para graficar comparaci√≥n observado vs simulado.
        
        Args:
            modelo: Nombre del modelo ('Vasicek', 'Hull-White')
            entidad: Tipo de cr√©dito o ID de cr√©dito espec√≠fico
            
        Returns:
            Dict con arrays para graficar
        """
        if modelo not in self.resultados_validacion:
            logger.warning(f"‚ö†Ô∏è Modelo {modelo} no tiene validaci√≥n disponible")
            return {}
        
        resultados = self.resultados_validacion[modelo]
        
        # Para Vasicek: entidad es tipo de cr√©dito
        if modelo == 'Vasicek' and 'metricas_por_tipo' in resultados:
            if entidad and entidad in resultados['metricas_por_tipo']:
                return {
                    'tipo': 'vasicek',
                    'entidad': entidad,
                    'metricas': resultados['metricas_por_tipo'][entidad]
                }
        
        # Para Hull-White: entidad es ID de cr√©dito
        if modelo == 'Hull-White' and 'metricas_por_credito' in resultados:
            if entidad and entidad in resultados['metricas_por_credito']:
                return {
                    'tipo': 'hull_white',
                    'entidad': entidad,
                    'metricas': resultados['metricas_por_credito'][entidad]
                }
        
        return {}
    
    def generar_semaforo(self) -> Dict:
        """
        Genera sistema de sem√°foro con colores seg√∫n umbrales de R¬≤.
        
        Umbrales basados en R¬≤:
        - Verde (Muy Bueno): R¬≤ >= 0.65
        - Amarillo (Aceptable): 0.40 <= R¬≤ < 0.65
        - Rojo (Bajo): R¬≤ < 0.40
        
        Returns:
            Dict con colores y calificaciones por modelo y entidad
        """
        logger.info("üö¶ Generando sem√°foro de calidad...")
        
        semaforo = {}
        
        for modelo, resultados in self.resultados_validacion.items():
            semaforo[modelo] = {}
            
            # Para Vasicek: usar R¬≤ por tipo
            if modelo == 'Vasicek' and 'metricas_por_tipo' in resultados:
                for tipo, metricas in resultados['metricas_por_tipo'].items():
                    r2 = metricas.get('r_cuadrado', 0)
                    semaforo[modelo][tipo] = self._clasificar_metrica(r2)
            
            # Para Hull-White: usar R¬≤ por cr√©dito
            elif 'metricas_por_credito' in resultados:
                for credito, metricas in resultados['metricas_por_credito'].items():
                    r2 = metricas.get('r_cuadrado', 0)
                    semaforo[modelo][credito] = self._clasificar_metrica(r2)
            
            # Clasificaci√≥n global del modelo
            if 'metricas_globales' in resultados:
                r2_prom = resultados['metricas_globales'].get('r_cuadrado_promedio')
                if r2_prom is not None:
                    semaforo[modelo]['GLOBAL'] = self._clasificar_metrica(r2_prom)
        
        logger.info(f"‚úÖ Sem√°foro generado para {len(semaforo)} modelos")
        return semaforo
    
    def _clasificar_metrica(self, valor: float) -> Dict:
        """
        Clasifica una m√©trica seg√∫n umbrales y asigna color y etiqueta.
        
        Args:
            valor: Valor de la m√©trica (R¬≤, tasa de √©xito, etc.)
            
        Returns:
            Dict con color, etiqueta y valor
        """
        if valor >= 0.65:
            return {
                'color': 'verde',
                'color_hex': '#2ecc71',
                'etiqueta': 'MUY BUENO',
                'emoji': 'üü¢',
                'valor': round(valor, 4)
            }
        elif valor >= 0.40:
            return {
                'color': 'amarillo',
                'color_hex': '#f39c12',
                'etiqueta': 'ACEPTABLE',
                'emoji': 'üü°',
                'valor': round(valor, 4)
            }
        else:
            return {
                'color': 'rojo',
                'color_hex': '#e74c3c',
                'etiqueta': 'BAJO',
                'emoji': 'üî¥',
                'valor': round(valor, 4)
            }
