import numpy as np
import pandas as pd
import logging
from typing import Dict, Tuple
from scipy.optimize import minimize

logger = logging.getLogger(__name__)

def _nll_ou_var_dt(params: np.ndarray, data: np.ndarray, dts: np.ndarray) -> float:
    """
    Funci√≥n de log-verosimilitud negativa para el modelo Vasicek/OU.
    
    F√ìRMULAS MLE (seg√∫n tesis - Maximum Likelihood Estimator Method):
        E[r_{t+s} | r_t] = Œ∏ + (r_t - Œ∏)e^{-Œ∫s}
        Var[r_{t+s} | r_t] = (œÉ¬≤/2Œ∫)(1 - e^{-2Œ∫s})
    
    donde:
        Œ∫ (kappa): velocidad de reversi√≥n a la media
        Œ∏ (theta): nivel de largo plazo (media de largo plazo)
        œÉ (sigma): volatilidad
        s: intervalo de tiempo entre observaciones
    """
    try:
        kappa, theta, sigma = float(params[0]), float(params[1]), float(params[2])
    except Exception:
        return np.inf
    if not np.isfinite(kappa) or not np.isfinite(theta) or not np.isfinite(sigma):
        return np.inf
    if kappa <= 0.0 or sigma <= 0.0:
        return np.inf
    if dts is None or len(dts) == 0:
        return np.inf
    r_t = data[1:]
    r_tm1 = data[:-1]
    if len(r_tm1) != len(dts):
        n = min(len(r_tm1), len(dts))
        r_t = r_t[:n]
        r_tm1 = r_tm1[:n]
        dts = dts[:n]
    
    # F√≥rmula MLE: E[r_{t+s} | r_t] = Œ∏ + (r_t - Œ∏)e^{-Œ∫s}
    exp_kdt = np.exp(-kappa * dts)
    mean = theta + (r_tm1 - theta) * exp_kdt
    
    # F√≥rmula MLE: Var[r_{t+s} | r_t] = (œÉ¬≤/2Œ∫)(1 - e^{-2Œ∫s})
    var = (sigma**2 / (2.0 * kappa)) * (1.0 - np.exp(-2.0 * kappa * dts))
    
    if not np.all(np.isfinite(var)) or np.any(var <= 0.0):
        return np.inf
    nll = 0.5 * np.sum(np.log(2.0 * np.pi * var) + ((r_t - mean) ** 2) / var)
    return float(nll)

def calibrar_parametros_vasicek_mle_por_tipo(df_tasas_mercado: pd.DataFrame) -> Tuple[Dict[str, Dict[str, float]], Dict[str, Dict[str, float]]]:
    logger.info("üîß Iniciando calibraci√≥n MLE de Vasicek por tipo de cr√©dito con transformaci√≥n EA ‚Üí Short Rate...")

    df = df_tasas_mercado.copy()
    df['Fecha'] = pd.to_datetime(df['Fecha'], format='%d/%m/%Y')
    df = df.set_index('Fecha').sort_index()

    tipos_credito_validos = [col for col in df.columns if col in ["Comercial", "Consumo", "Vivienda"]]
    if not tipos_credito_validos:
        raise ValueError("El DataFrame debe contener al menos una de las columnas: 'Comercial', 'Consumo', 'Vivienda'.")

    parametros_base = {}

    for tipo_credito in tipos_credito_validos:
        tasas_ea = df[tipo_credito].dropna()
        if tasas_ea.max() > 1.0 and tasas_ea.max() <= 100.0:
            tasas_ea = tasas_ea / 100.0
        if len(tasas_ea) < 3:
            logger.warning(f"'{tipo_credito}' tiene menos de 3 observaciones. Se omite.")
            continue
        
        # TRANSFORMACI√ìN CR√çTICA: EA ‚Üí Short Rate usando ln(1 + r)
        logger.info(f"üìä Transformando {len(tasas_ea)} tasas EA ‚Üí Short Rates para {tipo_credito}")
        tasas_short = pd.Series(np.log1p(tasas_ea.values), index=tasas_ea.index)
        logger.debug(f"üîç {tipo_credito}: EA rango [{tasas_ea.min():.6f}, {tasas_ea.max():.6f}] ‚Üí Short rango [{tasas_short.min():.6f}, {tasas_short.max():.6f}]")
        
        # Usar tasas short para calibraci√≥n
        tasas = tasas_short

        # MLE OU con Œî variable por observaci√≥n
        r = tasas.values.astype(float)
        if len(r) < 3:
            logger.warning(f"'{tipo_credito}' tiene menos de 3 observaciones tras conversi√≥n. Se omite.")
            continue

        # Forzar Œî semanal fijo para coherencia con simulaci√≥n y control de varianza del paso
        # (si se requiere volver a Œî variable, restaurar el c√°lculo con diferencias de fechas)
        idx = tasas.index
        dts = np.full(len(r) - 1, 7.0/365.0, dtype=float)
        dr = np.diff(r)
        kappa_init = 0.2
        theta_init = float(np.mean(r))
        mean_dt = float(np.mean(dts)) if len(dts) > 0 else (7.0/365.0)
        sigma_init = float(np.std(dr) / np.sqrt(mean_dt)) if len(dr) > 1 else 0.01
        sigma_init = max(sigma_init, 1e-4)

        x0 = np.array([kappa_init, theta_init, sigma_init], dtype=float)
        
        # BOUNDS MEJORADOS: Evitar convergencia a par√°metros no razonables
        # kappa: M√≠nimo 0.01 (reversi√≥n en ~69 semanas), sin m√°ximo
        # theta: Usar rango razonable basado en los datos
        #        M√≠nimo: 70% de la media de los datos (permite ajuste pero no colapso)
        #        M√°ximo: 150% de la media de los datos (permite crecimiento)
        # sigma: Positivo, sin m√°ximo
        kappa_min = 0.01
        theta_min = max(0.7 * theta_init, 0.05)  # M√≠nimo 70% de media, o 5% EA
        theta_max = min(1.5 * theta_init, 0.69)  # M√°ximo 150% de media, o 100% EA
        
        bounds = ((kappa_min, None), (theta_min, theta_max), (1e-6, None))
        
        logger.info(f"   üîí Bounds aplicados: Œ∫‚â•{kappa_min}, Œ∏‚àà[{theta_min},{theta_max}], œÉ>0")
        
        # Calcular NLL inicial (valor de partida)
        nll_inicial = _nll_ou_var_dt(x0, r, dts)
        logger.info(f"   üéØ MLE - Valores iniciales: Œ∫={kappa_init:.4f}, Œ∏={theta_init:.4f}, œÉ={sigma_init:.4f}")
        logger.info(f"   üìâ NLL inicial: {nll_inicial:.4f}")
        
        try:
            # Ejecutar optimizaci√≥n MLE
            res = minimize(_nll_ou_var_dt, x0=x0, args=(r, dts), method="L-BFGS-B", bounds=bounds)
            
            # Calcular NLL final
            nll_final = res.fun
            mejora = nll_inicial - nll_final
            mejora_pct = (mejora / abs(nll_inicial)) * 100 if nll_inicial != 0 else 0
            
            logger.info(f"   üîÑ MLE - Iteraciones: {res.nit}, Convergencia: {'‚úì' if res.success else '‚úó'}")
            logger.info(f"   üìà NLL final: {nll_final:.4f} (mejora: {mejora:.4f}, {mejora_pct:.2f}%)")
            
            if res.success and np.all(np.isfinite(res.x)):
                kappa_mle, theta_mle, sigma_mle = map(float, res.x)
                logger.info(f"   ‚úÖ Optimizaci√≥n exitosa")
            else:
                logger.warning(f"   ‚ö†Ô∏è Optimizaci√≥n no convergi√≥, usando valores iniciales")
                logger.warning(f"   Mensaje: {res.message}")
                kappa_mle, theta_mle, sigma_mle = map(float, x0)
        except Exception as e:
            logger.error(f"   ‚ùå Error en optimizaci√≥n MLE: {e}")
            logger.error(f"   Usando valores iniciales como fallback")
            kappa_mle, theta_mle, sigma_mle = map(float, x0)

        parametros_base[tipo_credito] = {
            "kappa": round(float(kappa_mle), 6),
            "theta": round(float(theta_mle), 6),  # theta en short rate space
            "sigma": round(float(sigma_mle), 6)   # sigma en short rate space
        }
        
        # CONVERSI√ìN PARA LOGGING: mostrar theta equivalente en EA para referencia
        theta_ea_equiv = np.exp(theta_mle) - 1
        logger.info(f"‚úÖ PAR√ÅMETROS CALIBRADOS (SHORT RATES) - {tipo_credito}: {parametros_base[tipo_credito]}")
        logger.info(f"üìä Theta equivalente en EA: {theta_ea_equiv:.6f} ({theta_ea_equiv*100:.2f}%)")
        
        # Reporte de equivalentes AR(1) (Œî semanal) para auditor√≠a con la lectura
        delta_ref = 7.0/365.0
        beta_star = float(np.exp(-kappa_mle * delta_ref))
        alpha_star = float((1.0 - beta_star) * theta_mle)
        sigma_star = float(np.sqrt((sigma_mle**2 / (2.0 * kappa_mle)) * (1.0 - np.exp(-2.0 * kappa_mle * delta_ref))))
        logger.info(f"üìë Equivalente AR(1) (Œî=7/365): alpha*={alpha_star:.6f}, beta*={beta_star:.6f}, sigma*={sigma_star:.6f}")

    if not parametros_base:
        raise RuntimeError("No se pudo calibrar ning√∫n tipo de cr√©dito con √©xito.")

    parametros_estresados = {
        tipo: {
            "kappa": p["kappa"],
            "theta": p["theta"],
            "sigma": round(p["sigma"] * 1.25, 6)
        }
        for tipo, p in parametros_base.items()
    }

    logger.info("Par√°metros estresados generados (œÉ √ó 1.25):")
    for tipo, p in parametros_estresados.items():
        logger.info(f"{tipo} (estresado): {p}")

    return parametros_base, parametros_estresados
